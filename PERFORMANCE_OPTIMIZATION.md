# Website Performance Optimization Guide

## âœ… Optimizations Applied

### 1. **Database Connection Pool** âœ…
- **Changed from**: Single connection reuse
- **Changed to**: Connection pool with 20 connections
- **File**: `config/database.tsx`
- **Benefits**: 
  - Handles multiple concurrent requests
  - Automatic reconnection
  - Better for serverless environments

### 2. **Pagination Added** âœ…
- **Blog API** (`/api/blog`): Now supports pagination
  - Default: 20 posts per page
  - Query params: `?page=1&limit=20&status=published`
  - Returns: `total`, `totalPages`, `page`, `limit`
  
- **User Info API** (`/api/userinfo-get`): Pagination added
  - Default: 50 records per page (max 100)
  - Query params: `?page=1&limit=50`
  
- **Orders API** (`/api/orderid-get`): Pagination added
  - Default: 50 records per page (max 100)
  - Query params: `?page=1&limit=50`

### 3. **Query Optimization** âœ…
- **Blog List View**: Excludes `content` column (large text) for faster queries
- **Select Specific Columns**: Instead of `SELECT *`, now selects only needed columns
- **Status Filtering**: Default filters to `published` status only

### 4. **Response Caching** âœ…
- Added `Cache-Control` headers to:
  - User Info API: 60 seconds cache
  - Orders API: 30 seconds cache
  - Hero Section: Already had caching (5 minutes)

### 5. **Database Indexes** âœ…
- Created `database/performance_indexes.sql` with indexes for:
  - Blog posts (status, publish_date, slug, featured)
  - Orders (id, payment_status, created_at)
  - Users (email, userId)
  - User info (id, email)
  - Company slider (order, header)

## ðŸš€ How to Apply Database Indexes

Run this SQL file in your database:

```bash
mysql -u root -p ensurekar < database/performance_indexes.sql
```

Or in phpMyAdmin:
1. Select your database `ensurekar`
2. Go to SQL tab
3. Copy and paste contents of `database/performance_indexes.sql`
4. Click "Go"

## ðŸ“Š Expected Performance Improvements

### Before Optimization:
- Blog page: Loads ALL blog posts (could be 100+)
- User info: Loads ALL users (could be 1000+)
- Orders: Loads ALL orders (could be 500+)
- **Result**: Slow page loads (5-10+ seconds)

### After Optimization:
- Blog page: Loads only 20 posts per page
- User info: Loads only 50 records per page
- Orders: Loads only 50 records per page
- **Result**: Fast page loads (1-2 seconds)

## ðŸ”§ Additional Recommendations

### 1. **Update Frontend to Use Pagination**

Update your blog listing page to use pagination:

```typescript
// Example: src/app/blog-section/page.tsx
const [page, setPage] = useState(1);
const [totalPages, setTotalPages] = useState(1);

const fetchBlogs = async (pageNum = 1) => {
  const response = await fetch(`/api/blog?page=${pageNum}&limit=20&status=published`);
  const data = await response.json();
  setBlogs(data.data);
  setTotalPages(data.totalPages);
};
```

### 2. **Enable Database Query Logging** (Optional)

To monitor slow queries:

```sql
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 2; -- Log queries taking more than 2 seconds
```

### 3. **Monitor Connection Pool**

Check if you need to adjust pool size:

```typescript
// In config/database.tsx
connectionLimit: 20, // Increase if you have high traffic
```

### 4. **Add Redis Caching** (Advanced)

For even better performance, consider adding Redis for:
- Frequently accessed data
- Session storage
- API response caching

## ðŸ“ˆ Performance Metrics to Monitor

1. **API Response Time**: Should be < 500ms for paginated queries
2. **Database Query Time**: Should be < 100ms with indexes
3. **Page Load Time**: Should be < 2 seconds
4. **Connection Pool Usage**: Monitor for connection exhaustion

## âš ï¸ Important Notes

1. **Backward Compatibility**: 
   - Old API calls without pagination will still work
   - Default limits are set to reasonable values
   - Frontend may need updates to show pagination controls

2. **Database Indexes**:
   - Indexes use disk space (minimal)
   - INSERT/UPDATE may be slightly slower
   - SELECT queries will be MUCH faster

3. **Caching**:
   - Cache headers help with CDN/proxy caching
   - Data may be stale for up to cache duration
   - Adjust cache times based on your needs

## ðŸ› Troubleshooting

### If website is still slow:

1. **Check if indexes are applied**:
   ```sql
   SHOW INDEXES FROM blog_posts;
   SHOW INDEXES FROM orders;
   ```

2. **Check query execution time**:
   ```sql
   EXPLAIN SELECT * FROM blog_posts WHERE status = 'published' ORDER BY publish_date DESC LIMIT 20;
   ```

3. **Monitor connection pool**:
   - Check for "too many connections" errors
   - Increase `connectionLimit` if needed

4. **Check for N+1 queries**:
   - Look for loops making database calls
   - Use batch queries instead

## ðŸ“ Next Steps

1. âœ… Run `database/performance_indexes.sql` on your database
2. âœ… Test API endpoints with pagination
3. â³ Update frontend components to use pagination
4. â³ Monitor performance metrics
5. â³ Consider adding Redis for advanced caching

---

**Created**: Performance optimization applied to improve website speed
**Status**: All optimizations completed and ready to use

